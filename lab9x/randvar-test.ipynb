{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "source": [
    "# Important note!\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your GT login and the GT logins of any of your collaborators below. (The GT logins are worth 1 point per notebook, so don't miss the opportunity to get a free point!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "YOUR_ID = \"\" # Please enter your GT login, e.g., \"rvuduc3\" or \"gtg911x\"\n",
    "COLLABORATORS = [] # list of strings of your collaborators' IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b11295002cc2b9549d6a2b01721b6701",
     "grade": true,
     "grade_id": "who__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "RE_CHECK_ID = re.compile (r'''[a-zA-Z]+\\d+|[gG][tT][gG]\\d+[a-zA-Z]''')\n",
    "assert RE_CHECK_ID.match (YOUR_ID) is not None\n",
    "\n",
    "collab_check = [RE_CHECK_ID.match (i) is not None for i in COLLABORATORS]\n",
    "assert all (collab_check)\n",
    "\n",
    "del collab_check\n",
    "del RE_CHECK_ID\n",
    "del re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter / IPython version check.** The following code cell verifies that you are using the correct version of Jupyter/IPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Random Variates and Testing Random Number Generators\n",
    "\n",
    "This notebook accompanies the slides presented in class: TBD (see T-Square or Piazza)\n",
    "\n",
    "For a deeper survey of these ideas, see the readings from the last lab, especially volume 2 of Knuth's _The Art of Computer Programming_: [link](https://t-square.gatech.edu/access/content/group/gtc-239f-fc11-5690-9dae-2dc96b59f372/Knuth-TAOCP-v2--9780133488791.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From uniform to arbitrary distributions\n",
    "\n",
    "Suppose you are given a way to generate a uniform random variable $U \\sim \\mathcal{U}(0, 1)$. How do you convert $U$ into a different random variable $X$ following some _other_ distribution, such as exponential?\n",
    "\n",
    "One technique is to \"invert\" the _cumulative distribution function_ (CDF) of $X$. Recall that the CDF of $X$ is a function\n",
    "\n",
    "$$\n",
    "  F_X(x) \\equiv \\mathrm{Pr}[X \\leq x].\n",
    "$$\n",
    "\n",
    "Given a sample value $u$ of the random variable $U$, you can convert $u$ into a sample $x$ of $X$ by\n",
    "\n",
    "$$\n",
    "  x = F_X^{-1}(u).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.** Let $X \\sim \\mathcal{E}(\\lambda)$ be an exponentially distributed random variable with mean $\\lambda$. Then it has a cumulative distribution\n",
    "\n",
    "$$\n",
    "  F_X(x) = 1 - e^{-x / \\lambda}.\n",
    "$$\n",
    "\n",
    "Given an observed sample $u$ of a random variable $U$, you would compute the sample $x$ by solving $u = F_X^{-1}(x)$ for $x$. The result would be\n",
    "\n",
    "$$\n",
    "  x = {-\\lambda \\ln (1-u)}\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Implement a function to generate samples from $\\mathcal{E}(\\lambda)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "f531ca06a1aa9a07a49fc1583e69769d",
     "grade": false,
     "grade_id": "sample_exp",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from random import random, seed\n",
    "from math import log\n",
    "\n",
    "def sample_exp (l):\n",
    "    \"\"\"Generates a sample from an exponential random variable with mean `l`.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test code: Generate samples and plot them as a histogram\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n = 250\n",
    "l = 5.0\n",
    "seed (20160224)\n",
    "x = [sample_exp (l) for i in range (n)]\n",
    "\n",
    "x_mean = sum (x) / n\n",
    "print (\"Sample mean:\", x_mean)\n",
    "plt.hist (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating samples for an empirical CDF\n",
    "\n",
    "You can apply essentially the same idea to discrete random variables. Let's walk through an example.\n",
    "\n",
    "Suppose you wish to generate letters from a distribution that matches the empirically observed distribution of letters in the English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests # http://docs.python-requests.org/en/master/user/quickstart/#make-a-request\n",
    "\n",
    "def download_text (url):\n",
    "    print (\"... downloading\", url, \"...\")\n",
    "    req = requests.get (url)\n",
    "    return req.text\n",
    "\n",
    "text = download_text ('http://www.gutenberg.org/cache/epub/11/pg11.txt')\n",
    "#text = download_text ('http://www.gutenberg.org/cache/epub/15532/pg15532.txt')\n",
    "print (\"\\n=== Snippet ===\\n...\", text[5000:5500], \"\\n...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** From what book was this text drawn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer: ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's make a histogram of letter frequencies, stored as a dictionary where the key is the letter and the value is the number of occurrences of that letter. For simplicity, consider only alphabetic characters and normalize all characters to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a histogram of individual characters. See: https://docs.python.org/2/library/collections.html\n",
    "from collections import Counter\n",
    "\n",
    "def count_chars (s):\n",
    "    \"\"\"\n",
    "    Given a string or list of characters `s`, this function returns a\n",
    "    histogram of the number of occurrences of alphabetic characters.\n",
    "    The histogram is stored as a dictionary and the characters are\n",
    "    normalized to lowercase.\n",
    "    \"\"\"\n",
    "    histogram = Counter ()\n",
    "    for c in s:\n",
    "        if c.isalpha ():\n",
    "            histogram[c.lower ()] += 1\n",
    "    return histogram\n",
    "\n",
    "# Count the occurrences of each (lowercase) alphabetic characters\n",
    "text_counts = count_chars (text)\n",
    "num_chars = sum (text_counts.values ())\n",
    "print (\"=== Occurrences:\", num_chars, \"characters total ===\")\n",
    "text_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this distribution a little easier to read, let's convert it to a list and sort by value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A function to \"sort\" dictionaries:\n",
    "# http://stackoverflow.com/questions/613183/sort-a-python-dictionary-by-value\n",
    "import operator\n",
    "\n",
    "def sort_dict (d, descending=False):\n",
    "    \"\"\"\n",
    "    Given a dictionary `d`, returns a list of (key, value) pairs sorted by value.\n",
    "    To sort in descending order, set `ascending=False`.\n",
    "    \"\"\"\n",
    "    if descending:\n",
    "        compare = lambda x: -(operator.itemgetter (1) (x))        \n",
    "    else:\n",
    "        compare = operator.itemgetter (1)\n",
    "    return sorted (d.items (), key=compare)\n",
    "\n",
    "text_counts_sorted = sort_dict (text_counts, descending=True)\n",
    "text_counts_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert these ordered counts into a CDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cumsum_key_value_pairs (p):\n",
    "    s = 0.0\n",
    "    p_cumulative = []\n",
    "    for (k, v) in p:\n",
    "        s = s + v\n",
    "        p_cumulative.append ((k, s))\n",
    "    return p_cumulative\n",
    "\n",
    "text_cdf = [(k, float (v)/num_chars) for (k, v) in cumsum_key_value_pairs (text_counts_sorted)]\n",
    "print (\"=== Empirical CDF ===\")\n",
    "text_cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Write a function to generate a sample from a discrete CDF like `text_cdf`. Recall that `text_cdf` is a list of (key, value) pairs where the key is an outcome of the random variable and the value is the cumulative probability of observing the key and all preceding keys in list order.\n",
    "\n",
    "> Hint: The [`bisect()`](https://docs.python.org/2/library/bisect.html) makes this task easy. In particular, given a list `X` of values in ascending order, `bisect(X, v)` returns the largest index `i` such `X[i] <= v`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a269d03873c7e4ee6a9398522a0183df",
     "grade": false,
     "grade_id": "gen_sample",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from bisect import bisect # Per the hint\n",
    "\n",
    "def gen_sample (cdf):\n",
    "    \"\"\"\n",
    "    Given a discrete cumulative distribution function, this function returns\n",
    "    a single random sample from the distribution. The input CDF is given as\n",
    "    a list `cdf` of (`key`, `value`) pairs, where `value` is the cumulative\n",
    "    probability of observing the key and all preceding keys in the list.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test code: Generate `n` samples and count the occurrences of each unique character.\n",
    "n = 1000\n",
    "sample = [gen_sample (text_cdf) for i in range (n)]\n",
    "sort_dict (count_chars (sample), descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-square ($\\chi^2$) testing\n",
    "\n",
    "**Overview.** The previous example began with a \"true\" (empirical) distribution of letter frequencies, extracted from text real text. We then generated samples from this distribution.\n",
    "\n",
    "What if we had just been handed the generated samples. How could we check whether they came from our letter-frequency distribution? \n",
    "\n",
    "In class, we discussed one way to test how likely a random sample was to have been drawn from a given discrete distribution, using a method called the _chi-square ($\\chi^2$) test_. There are canned (black-box) routines to compute it, e.g., [`scipy.stats.chisquare()`](http://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.stats.chisquare.html). Here is how we would apply it to the data for the pair of dice in the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "# Check against slide data\n",
    "X_slides = [4, 8, 12, 16, 20, 24, 20, 16, 12, 8, 4]\n",
    "Y_slides = [2, 4, 10, 12, 22, 29, 21, 15, 14, 9, 6]\n",
    "chisquare (Y_slides, f_exp=X_slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for pedagogical purposes, let's see how it works the black-box actually works through a series of exercises. In these exercises, assume that the `sample` dictionary computed above is the set of values we are testing against a \"true\" distribution, which comes from the text (`text_counts`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Walk-through.** Per the class slides, consider a discrete distribution for which you know that any outcome $v$ occurs with probability $p_v$. You observe a random sample of size $n$, $\\{y_0, y_1, \\ldots, y_{n-1}\\}$. You wish to check how likely it is to have come from the given distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Convert the letter counts into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7d8f56151a9d0559a2b2cd6d3f74b014",
     "grade": false,
     "grade_id": "text_probs",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# @YOUSE: Compute a new dictionary of key-value pairs, (v, p_v), from `text_counts`.\n",
    "#text_probs = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "text_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compute the _counts_ of the number of occurrences of $v$ in the sample. Denote these observed counts mathematically by $Y_v$.\n",
    "\n",
    "**Exercise.** Compute a dictionary `sample_counts[k] = c` where `k` is $v$ and `c` is $Y_v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d28d3ffc6409ffaefb6eb1ccc16dc10c",
     "grade": false,
     "grade_id": "sample_counts",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# @YOUSE: Compute:\n",
    "#sample_counts = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Display\n",
    "sample_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compute the _chi-square statistic_, which is\n",
    "\n",
    "$$\n",
    "  \\chi^2 \\equiv \\sum_v \\dfrac{(Y_v - np_v)^2}{np_v},\n",
    "$$\n",
    "\n",
    "where $np_v$ is the expected number of occurrences of $v$ in a sample of size $n$.\n",
    "\n",
    "**Exercise.** Complete the following function, which computes the $\\chi^2$ statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "c86976da28cf8ebb5466d49998dab910",
     "grade": false,
     "grade_id": "chisq",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_chisquare_statistic (counts, probs):\n",
    "    \"\"\"\n",
    "    Given a target distribution and empirically observed counts, compute the\n",
    "    chi-square statistic of the observations relative to the target.\n",
    "    \n",
    "    The input `counts[v] = y_v` is the dictionary of observations and\n",
    "    `probs[v] = p_v` is the probability of observing `v`.\n",
    "    \"\"\"\n",
    "    n = sum (counts.values ())\n",
    "    chi_sq = 0.0\n",
    "    \n",
    "    # @YOUSE: Compute `chi_sq`\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return chi_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_chi2 = calc_chisquare_statistic (sample_counts, text_probs)\n",
    "print (\"\\nchi^2 for the random sample:\", sample_chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the $\\chi^2$ statistic, you also need to know the number of degrees of freedom of the distribution.\n",
    "\n",
    "**Exercise.** Compute the degrees of freedom of the target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# ANSWER:\n",
    "text_dof = len (text_probs) - 1\n",
    "print (\"Degrees of freedom =\", text_dof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you would \"look up\" the chances of observing your $\\chi^2$ given the number of degrees of freedom. In Python, you can do this look-up by calling a function that evaluates the CDF of a $\\chi^2$ distribution. See: http://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.stats.chi2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "chi2_stat_check = chi2.cdf (sample_chi2, text_dof)\n",
    "chi2_stat_check2 = 1 - chi2_stat_check\n",
    "print (\"chi^2 CDF:\", chi2_stat_check, \"/\", chi2_stat_check2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** What would you conclude about the likelihood that the random sample came from the target distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer: ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check.** Let's double-check your result against what the \"canned\" routine produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_chisquare (sample, probs):\n",
    "    assert (type (sample) is dict) or (type (sample) is Counter) # Counts\n",
    "    assert type (probs) is dict # Probabilities\n",
    "    \n",
    "    # Total number of samples\n",
    "    n_Y = sum (sample.values ())\n",
    "\n",
    "    Y = [] # Holds observed counts, $Y_v$ \n",
    "    X = [] # Holds expected counts, $X_v$\n",
    "\n",
    "    for (v, p_v) in probs.items (): # probabilities of the true distribution\n",
    "        x_v = p_v * n_Y\n",
    "        if v in sample:\n",
    "            y_v = sample[v]\n",
    "        else:\n",
    "            y_v = 0\n",
    "        X.append (x_v)\n",
    "        Y.append (y_v)\n",
    "    \n",
    "    return (chisquare (Y, f_exp=X), X, Y)\n",
    "\n",
    "chi2_result, _, _ = calc_chisquare (sample_counts, text_probs)\n",
    "print (chi2_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra stuff: English vs. Spanish\n",
    "\n",
    "How does the frequency distribution of English differ from Spanish? Let's download an example of Spanish text, compute the letter frequencies, and compare that distribution against the one for the English text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Spanish contains a number of vowels that don't occur in English. To make this comparable, the [`unidecode` package](https://pypi.python.org/pypi/Unidecode) can normalize a general unicode string into its closest pure ASCII representation. However, since `unidecode` is not a part of most standard Python distributions, you might need to install it first (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Downloads and installs the unidecode module; see: https://pypi.python.org/pypi/Unidecode\n",
    "!pip install unidecode\n",
    "\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_es = download_text ('http://www.gutenberg.org/cache/epub/15532/pg15532.txt')\n",
    "# If you don't have unidecode, just comment this next line out:\n",
    "text_es = unidecode (text_es)\n",
    "print (\"\\n=== Snippet (Spanish text) ===\\n...\", text_es[5000:5500], \"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_es_counts = count_chars (text_es)\n",
    "sort_dict (text_es_counts, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_chars_es = sum (text_es_counts.values ())\n",
    "text_es_probs = {k: v/num_chars_es for (k, v) in text_es_counts.items ()}\n",
    "text_es_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_probs_sorted = sort_dict (text_probs, descending=True)\n",
    "x_labels = [k for (k, _) in text_probs_sorted]\n",
    "y_values = [v for (_, v) in text_probs_sorted]\n",
    "\n",
    "y_values_es = []\n",
    "for v in x_labels:\n",
    "    if v in text_es_probs:\n",
    "        y_v = text_es_probs[v]\n",
    "    else:\n",
    "        y_v = 0.0\n",
    "    y_values_es.append (y_v)\n",
    "\n",
    "x_values = range (len (x_labels))\n",
    "w = 0.25\n",
    "fig = plt.figure (figsize=(16, 6))\n",
    "ax = fig.add_subplot (111)\n",
    "ax.bar ([x-w for x in x_values], y_values, w, color='b')\n",
    "ax.bar (x_values, y_values_es, w, color='r')\n",
    "ax.set_xticks (x_values)\n",
    "ax.set_xticklabels (x_labels)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calc_chisquare (text_es_counts, text_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
